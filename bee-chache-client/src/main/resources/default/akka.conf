
# akka服务器设置
akka {
  actor {
    # 该参数不能修改
    provider = "cluster"
    serialization-bindings {
      // "com.shrbank.bigdata.shrools.execution.message.MasterMessages$WorkerCreated"=kryo
    }
    serializers {
      # Define kryo serializer
      //kryo = "com.romix.akka.serialization.kryo.KryoSerializer"
    }
    //    serialization-identifiers {
    //      "com.romix.akka.serialization.kryo.KryoSerializer" = 41
    //    }

    kryo{
      type = "nograph"
      idstrategy = "automatic"
      buffer-size = 4096
      max-buffer-size = -1
      use-manifests = false
      use-unsafe = false
      //      implicit-registration-logging = true
      //      kryo-trace = true
      resolve-subclasses = true
      mappings {
        "com.shrbank.bigdata.shrools.execution.message.MasterMessages$WorkerCreated" = 20
      }
    }
    database-io-dispatcher {
      # Dispatcher is the name of the event-based dispatcher
      type = Dispatcher
      # What kind of ExecutionService to use
      executor = "fork-join-executor"
      # Configuration for the fork join pool
      fork-join-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 2
        # Parallelism (threads) ... ceil(available processors * factor)
        parallelism-factor = 2.0
        # Max number of threads to cap factor-based parallelism number to
        # Note that the parallelism-max does not set the upper bound on the total number of threads
        # allocated by the ForkJoinPool. It is a setting specifically talking about the number of hot
        # threads the pool keep running in order to reduce the latency of handling a new incoming task.
        # You can read more about parallelism in the JDK’s ForkJoinPool documentation.
        parallelism-max = 10
      }
      # Throughput defines the maximum number of messages to be
      # processed per actor before the thread jumps to the next actor.
      # Set to 1 for as fair as possible.
      throughput = 1000
    }
  }
  remote {
    log-remote-lifecycle-events = off
    # If this is "on", Akka will log all inbound messages at DEBUG level,
    # if off then they are not logged
    //    log-received-messages = on
    //
    //    # If this is "on", Akka will log all outbound messages at DEBUG level,
    //    # if off then they are not logged
    //    log-sent-messages = on
    netty.tcp {
      port = 0
    }
  }
  cluster {
    seed-nodes = ["akka.tcp://defaultCluster@169.254.18.45:2551"]

    roles=["seed","proxy"]
    seed-node-timeout = 5s
    retry-unsuccessful-join-after = off
    shutdown-after-unsuccessful-join-seed-nodes = 20s
    metrics.native-library-extract-folder=${user.dir}/target/native
    failure-detector{
      heartbeat-interval = 10s
      acceptable-heartbeat-pause = 30s
      expected-response-after = 5s
    }
  }
  persistence {
    journal {
      plugin = "akka.persistence.journal.leveldb-shared"
      leveldb-shared.store {
        # DO NOT USE 'native = off' IN PRODUCTION !!!
        native = off
        dir = "target/shared-journal"
      }
    }
    snapshot-store {
      plugin = "akka.persistence.snapshot-store.local"
      local.dir = "target/snapshots"
    }
    snapshot-store.plugin = "akka.persistence.snapshot-store.local"
    snapshot-store.local.dir = "target/snapshots"
  }
  extensions = ["akka.cluster.metrics.ClusterMetricsExtension"]
  # akka.extensions=["akka.cluster.metrics.ClusterMetricsExtension"]
  # extensions = ["com.romix.akka.serialization.kryo.KryoSerializationExtension$"]
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}